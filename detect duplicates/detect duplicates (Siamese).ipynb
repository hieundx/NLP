{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds\n",
    "rnd.seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question pairs:  404351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/questions.csv\")\n",
    "N = len(data)\n",
    "print('Number of question pairs: ', N)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 323480 Test set: 80871\n"
     ]
    }
   ],
   "source": [
    "N_train = int(N * 0.8)\n",
    "N_test = N - N_train\n",
    "data_train = data[:N_train]\n",
    "data_test = data[N_train:]\n",
    "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  120210\n",
      "Indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
     ]
    }
   ],
   "source": [
    "td_index = data_train['is_duplicate'] == 1\n",
    "td_index = [i for i, x in enumerate(td_index) if x]\n",
    "print('Number of duplicate questions: ', len(td_index))\n",
    "print('Indexes of first ten duplicate questions:', td_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "is_duplicate:  1\n"
     ]
    }
   ],
   "source": [
    "print(data_train['question1'][5])\n",
    "print(data_train['question2'][5])\n",
    "print('is_duplicate: ', data_train['is_duplicate'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_train = np.array(data_train['question1'][td_index])\n",
    "Q2_train = np.array(data_train['question2'][td_index])\n",
    "y_train = np.array(data_train['is_duplicate'][td_index])\n",
    "\n",
    "Q1_test = np.array(data_test['question1'])\n",
    "Q2_test = np.array(data_test['question2'])\n",
    "y_test  = np.array(data_test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING QUESTIONS:\n",
      "\n",
      "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
      "\n",
      "is_duplicate = 1 \n",
      "\n",
      "TESTING QUESTIONS:\n",
      "\n",
      "Question 1:  What Type of sex position would you like to do?\n",
      "Question 2:  What type of Quora swag would you be most likely to actually wear/use? \n",
      "\n",
      "is_duplicate = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_train[0])\n",
    "print('Question 2: ', Q2_train[0], '\\n')\n",
    "print('is_duplicate =', y_train[0], '\\n')\n",
    "\n",
    "print('TESTING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_test[0])\n",
    "print('Question 2: ', Q2_test[0], '\\n')\n",
    "print('is_duplicate =', y_test[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  120210\n",
      "The length of the training set is:   96168\n",
      "The length of the validation set is:  24042\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "cut_off = int(len(Q1_train) * 0.8)\n",
    "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
    "val_Q1, val_Q2 = Q1_train[cut_off:], Q2_train[cut_off:]\n",
    "print('Number of duplicate questions: ', len(Q1_train))\n",
    "print(\"The length of the training set is:  \", len(train_Q1))\n",
    "print(\"The length of the validation set is: \", len(val_Q1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120210,)\n",
      "(120210,)\n",
      "(240420,)\n"
     ]
    }
   ],
   "source": [
    "print(Q1_train.shape)\n",
    "print(Q2_train.shape)\n",
    "print(np.concatenate((Q1_train, Q2_train)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "text_vectorization = tf.keras.layers.TextVectorization(output_mode='int', split='whitespace',  standardize='strip_punctuation')\n",
    "text_vectorization.adapt(np.concatenate((Q1_train, Q2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "tf.Tensor(\n",
      "[ 7030     6   178    10  9364  2401 36549   773    13  6454 29179    30\n",
      "    28   481    45    98], shape=(16,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(Q1_train[0])\n",
    "print(text_vectorization(Q1_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siamese(text_vectorizer, vocab_size, d_feature=128):\n",
    "    branch = tf.keras.models.Sequential(name='seq')\n",
    "    branch.add(text_vectorizer)\n",
    "    branch.add(tf.keras.layers.Embedding(vocab_size, d_feature))\n",
    "    branch.add(tf.keras.layers.LSTM(d_feature, return_sequences=True))\n",
    "    branch.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    branch.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
    "\n",
    "    input1 = tf.keras.layers.Input(shape=(1,), dtype='string')\n",
    "    input2 = tf.keras.layers.Input(shape=(1,), dtype='string')\n",
    "\n",
    "    branch1 = branch(input1)\n",
    "    branch2 = branch(input2)\n",
    "\n",
    "    conc = tf.keras.layers.Concatenate(axis=1)([ branch1, branch2 ])\n",
    "\n",
    "    return tf.keras.models.Model(inputs=[input1, input2], outputs=conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Siamese(text_vectorization, vocab_size=text_vectorization.vocabulary_size())\n",
    "model.build(input_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " seq (Sequential)               (None, 128)          4919040     ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['seq[0][0]',                    \n",
      "                                                                  'seq[1][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,919,040\n",
      "Trainable params: 4,919,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, None)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         4787456   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 128)         131584    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,919,040\n",
      "Trainable params: 4,919,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.get_layer('seq').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Loss function\n",
    "Source: NLP Specialization - Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TripletLossFn(v1, v2,  margin=0.25):\n",
    "    scores = tf.linalg.matmul(v1, v2, transpose_b = True)\n",
    "    batch_size = tf.cast(tf.shape(v1)[0], scores.dtype) \n",
    "\n",
    "    # Mean negative\n",
    "    positive = tf.linalg.diag_part(scores)\n",
    "    negative_zero_on_duplicate = scores - tf.linalg.diag(positive)\n",
    "    mean_negative = tf.math.reduce_sum(negative_zero_on_duplicate, axis=1) / (batch_size - 1)\n",
    "\n",
    "    # Closest negative\n",
    "    diagonal_mask = tf.eye(batch_size) == 1\n",
    "    larger_than_diagonal_mask = negative_zero_on_duplicate > tf.expand_dims(positive, axis=1)\n",
    "    mask_exclude_positives = tf.cast(diagonal_mask | larger_than_diagonal_mask, scores.dtype)\n",
    "    negative_without_positive = negative_zero_on_duplicate - (2.0 * mask_exclude_positives)\n",
    "    closest_negative = tf.math.reduce_max(negative_without_positive, axis=1)\n",
    "\n",
    "    # Calculate triplet loss\n",
    "    triplet_loss1 = tf.maximum(0.0, margin - positive + closest_negative)\n",
    "    triplet_loss2 = tf.maximum(0.0, margin - positive + mean_negative)\n",
    "    triplet_loss = tf.math.reduce_sum(triplet_loss1 + triplet_loss2)\n",
    "    \n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TripletLoss(labels, out, margin=0.25):\n",
    "    _, out_size = out.shape # get embedding size\n",
    "    v1 = out[:,:int(out_size/2)] # Extract v1 from out\n",
    "    v2 = out[:,int(out_size/2):] # Extract v2 from out\n",
    "    return TripletLossFn(v1, v2, margin=margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(((train_Q1, train_Q2),tf.constant([1]*len(train_Q1))))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(((val_Q1, val_Q2),tf.constant([1]*len(val_Q1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(Siamese, TripletLoss, text_vectorizer, train_dataset, val_dataset, lr, train_steps):\n",
    "    model = Siamese(text_vectorizer, vocab_size=text_vectorizer.vocabulary_size())\n",
    "\n",
    "    model.compile(loss=TripletLoss, optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
    "\n",
    "    model.fit(train_dataset, epochs=train_steps, validation_data=val_dataset)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "376/376 [==============================] - 22s 27ms/step - loss: 22.8102 - val_loss: 10.8847\n",
      "Epoch 2/10\n",
      "376/376 [==============================] - 10s 26ms/step - loss: 7.5298 - val_loss: 8.9455\n",
      "Epoch 3/10\n",
      "376/376 [==============================] - 10s 25ms/step - loss: 5.6999 - val_loss: 8.1774\n",
      "Epoch 4/10\n",
      "376/376 [==============================] - 10s 27ms/step - loss: 5.0221 - val_loss: 7.8146\n",
      "Epoch 5/10\n",
      "376/376 [==============================] - 10s 27ms/step - loss: 4.7704 - val_loss: 7.4752\n",
      "Epoch 6/10\n",
      "376/376 [==============================] - 10s 25ms/step - loss: 4.5775 - val_loss: 7.4886\n",
      "Epoch 7/10\n",
      "376/376 [==============================] - 10s 27ms/step - loss: 4.4443 - val_loss: 7.5312\n",
      "Epoch 8/10\n",
      "376/376 [==============================] - 10s 25ms/step - loss: 4.3223 - val_loss: 7.4871\n",
      "Epoch 9/10\n",
      "376/376 [==============================] - 10s 27ms/step - loss: 4.2795 - val_loss: 7.5111\n",
      "Epoch 10/10\n",
      "376/376 [==============================] - 11s 28ms/step - loss: 4.1739 - val_loss: 7.3666\n"
     ]
    }
   ],
   "source": [
    "train_steps = 10\n",
    "batch_size = 256\n",
    "lr = 0.01\n",
    "\n",
    "train_generator = train_dataset.shuffle(\n",
    "    len(train_Q1),\n",
    "    seed=7, \n",
    "    reshuffle_each_iteration=True\n",
    ").batch(batch_size=batch_size)\n",
    "\n",
    "val_generator = val_dataset.shuffle(\n",
    "    len(val_Q1),\n",
    "    seed=7,\n",
    "    reshuffle_each_iteration=True\n",
    ").batch(batch_size=batch_size)\n",
    "\n",
    "model = train_model(\n",
    "    Siamese, \n",
    "    TripletLoss,\n",
    "    text_vectorization, \n",
    "    train_generator, \n",
    "    val_generator, \n",
    "    lr,\n",
    "    train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(test_Q1, test_Q2, y_test, threshold, model, batch_size=64, verbose=True):\n",
    "    y_pred = []\n",
    "    test_gen = tf.data.Dataset.from_tensor_slices(((test_Q1, test_Q2), None)).batch(batch_size=batch_size)\n",
    "    \n",
    "    pred = model.predict(test_gen)\n",
    "    _, n_feat = pred.shape\n",
    "    v1 = pred[:, :n_feat//2]\n",
    "    v2 = pred[:, n_feat//2:]\n",
    "    \n",
    "    d  = tf.reduce_sum(tf.multiply(v1, v2), axis=1) / (tf.norm(v1, axis=1) * tf.norm(v2, axis=1))\n",
    "    y_pred = tf.cast(d > threshold, tf.float64)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred, y_test), tf.float64))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(question1, question2, threshold=0.7, model=model, verbose=True):\n",
    "    generator = tf.data.Dataset.from_tensor_slices((([question1], [question2]),None)).batch(batch_size=1)\n",
    "    \n",
    "    v1v2 = model.predict(generator)\n",
    "    _, n_feat = v1v2.shape\n",
    "    v1 = v1v2[:, :n_feat//2]\n",
    "    v2 = v1v2[:, n_feat//2:]\n",
    "\n",
    "    d = tf.reduce_sum(tf.multiply(v1, v2), axis=1) / (tf.norm(v1, axis=1) * tf.norm(v2, axis=1))\n",
    "\n",
    "    res = d > threshold\n",
    "\n",
    "    if(verbose):\n",
    "        print(\"Q1  = \", question1, \"\\nQ2  = \", question2)\n",
    "        print(\"d   = \", d.numpy())\n",
    "        print(\"res = \", res.numpy())\n",
    "\n",
    "    return res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q1  =  When will I see you? \n",
      "Q2  =  When can I see you?\n",
      "d   =  [0.9817116]\n",
      "res =  [ True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('When will I see you?', 'When can I see you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q1  =  Is it possible to fly? \n",
      "Q2  =  Is it feasible to fly?\n",
      "d   =  [0.86791974]\n",
      "res =  [ True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Is it possible to fly?', 'Is it feasible to fly?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q1  =  What time is it? \n",
      "Q2  =  How old are you?\n",
      "d   =  [-0.02421507]\n",
      "res =  [False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('What time is it?', 'How old are you?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
